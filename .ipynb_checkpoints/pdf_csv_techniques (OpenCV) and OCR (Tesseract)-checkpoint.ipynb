{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3652a12-2b2c-43d7-8772-2d0b5dca0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1233eb-213a-4b89-8608-7199ae02f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing page 1\n",
      "Saved to temp_page_1.csv\n",
      "Processing page 2\n",
      "Saved to temp_page_2.csv\n",
      "Combined CSV saved to normal_table_output.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import tabula\n",
    "from pdf2image import convert_from_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set Tesseract path (adjust for your system)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Preprocess image for better OCR\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale if not already\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Increase contrast and sharpen\n",
    "    image = cv2.convertScaleAbs(image, alpha=1.5, beta=0)\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Detect table boundaries (improved with larger region and debug output)\n",
    "def detect_table(image):\n",
    "    # Edge detection with adjusted parameters\n",
    "    edges = cv2.Canny(image, 30, 100)\n",
    "    \n",
    "    # Dilate to connect table lines\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=2)  # Increased iterations\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"No contours found, using full image\")\n",
    "        return image, (0, 0, image.shape[1], image.shape[0])\n",
    "    \n",
    "    # Get largest contour (table)\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    \n",
    "    # Expand region significantly to ensure full table capture\n",
    "    padding = 50  # Increased padding\n",
    "    x, y, w, h = max(0, x-padding), max(0, y-padding), w+2*padding, h+2*padding\n",
    "    \n",
    "    # Ensure coordinates donâ€™t exceed image bounds\n",
    "    x, y = max(0, x), max(0, y)\n",
    "    w, h = min(w, image.shape[1]-x), min(h, image.shape[0]-y)\n",
    "    \n",
    "    table_region = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Save cropped region for debugging\n",
    "    cv2.imwrite(\"table_region_debug.png\", table_region)\n",
    "    print(f\"Table detected at (x={x}, y={y}, w={w}, h={h}). Saved as 'table_region_debug.png'\")\n",
    "    \n",
    "    return table_region, (x, y, w, h)\n",
    "\n",
    "# Extract text with OCR, tuned for tables\n",
    "def ocr_table(table_image):\n",
    "    # Custom config: PSM 6 (block of text), preserve interword spaces\n",
    "    custom_config = r'--oem 3 --psm 6 -c preserve_interword_spaces=1'\n",
    "    text = pytesseract.image_to_string(table_image, config=custom_config)\n",
    "    return text\n",
    "\n",
    "# Convert OCR text to structured table (improved parsing)\n",
    "def text_to_csv(text, output_file):\n",
    "    lines = [line for line in text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Debug: Print raw OCR text\n",
    "    print(f\"Raw OCR Text:\\n{text}\\n{'-'*50}\")\n",
    "    \n",
    "    # Filter out title text and keep potential table rows\n",
    "    table_lines = []\n",
    "    for line in lines:\n",
    "        if line.startswith('STANDARD NORMAL') or 'Z score' in line:\n",
    "            continue\n",
    "        # Relaxed condition: Look for lines with numbers, not just '|'\n",
    "        if any(char.isdigit() for char in line):\n",
    "            table_lines.append(line)\n",
    "    \n",
    "    if not table_lines:\n",
    "        raise ValueError(\"No table rows detected in OCR output\")\n",
    "    \n",
    "    # Process table lines\n",
    "    data = []\n",
    "    for line in table_lines:\n",
    "        # Split by whitespace or '|' (more flexible)\n",
    "        row = [cell.strip('$\\\\mathbf{').strip('}') for cell in line.replace('|', ' ').split() if cell.strip()]\n",
    "        # Relaxed length check: Accept rows with at least 2 columns (Z + some data)\n",
    "        if len(row) >= 2:\n",
    "            # Pad with empty strings if fewer than 11 columns\n",
    "            while len(row) < 11:\n",
    "                row.append('')\n",
    "            data.append(row[:11])  # Truncate to 11 if too long\n",
    "    \n",
    "    if not data:\n",
    "        raise ValueError(\"No valid table data parsed\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    headers = ['Z', '.00', '.01', '.02', '.03', '.04', '.05', '.06', '.07', '.08', '.09']\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(data)} rows to {output_file}\")\n",
    "\n",
    "# Handle multi-page PDF or image\n",
    "def extract_table_to_csv(input_file, output_csv=\"output.csv\"):\n",
    "    all_dfs = []\n",
    "    \n",
    "    if input_file.lower().endswith('.pdf'):\n",
    "        # Convert PDF to images\n",
    "        images = convert_from_path(input_file, poppler_path=r'C:\\Program Files\\poppler-23.11.0\\Library\\bin', dpi=300)\n",
    "        for i, image in enumerate(images):\n",
    "            print(f\"Processing page {i+1}\")\n",
    "            img_array = np.array(image)\n",
    "            img_gray = preprocess_image(img_array)\n",
    "            table_img, _ = detect_table(img_gray)\n",
    "            table_text = ocr_table(table_img)\n",
    "            temp_csv = f\"temp_page_{i+1}.csv\"\n",
    "            text_to_csv(table_text, temp_csv)\n",
    "            all_dfs.append(pd.read_csv(temp_csv))\n",
    "            os.remove(temp_csv)\n",
    "    else:\n",
    "        # Process single image\n",
    "        img = preprocess_image(cv2.imread(input_file))\n",
    "        table_img, _ = detect_table(img)\n",
    "        table_text = ocr_table(table_img)\n",
    "        text_to_csv(table_text, output_csv)\n",
    "        return\n",
    "    \n",
    "    # Combine all pages into one CSV\n",
    "    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Combined CSV saved to {output_csv} with {len(combined_df)} rows\")\n",
    "\n",
    "# Test with your PDF\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"table.pdf\"  # Replace with your file path\n",
    "    extract_table_to_csv(input_file, \"normal_table_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889beab-21ae-4819-81c8-629bf63f17a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
